{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKZjM3dcDG/uWoAuxEU2YX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ccce42429e574240b42392c5dfa7c6db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbca1917dc21442e93cfceb23d756100","IPY_MODEL_d468693a69464beba1646019feb3dea7","IPY_MODEL_40d4eec0fabf49d6bb48ee2ba202ff2c"],"layout":"IPY_MODEL_49812453de4b468390627355599005b3"}},"bbca1917dc21442e93cfceb23d756100":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b46f813072c4c748a16b8a34dbb3de5","placeholder":"​","style":"IPY_MODEL_714aa50f352049cf9777e3600114bed3","value":"Loading checkpoint shards: 100%"}},"d468693a69464beba1646019feb3dea7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf5eeae9ef69446d9562704dd80075ce","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7c08b2a93c74f3f9c5318040526b1da","value":2}},"40d4eec0fabf49d6bb48ee2ba202ff2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_289b17579d7d4f34865f92f4f9b03177","placeholder":"​","style":"IPY_MODEL_71888d259db74fd289556e3e519538e7","value":" 2/2 [00:42&lt;00:00, 19.96s/it]"}},"49812453de4b468390627355599005b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b46f813072c4c748a16b8a34dbb3de5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714aa50f352049cf9777e3600114bed3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf5eeae9ef69446d9562704dd80075ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7c08b2a93c74f3f9c5318040526b1da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"289b17579d7d4f34865f92f4f9b03177":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71888d259db74fd289556e3e519538e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"oRGgeFfOsYUd","executionInfo":{"status":"ok","timestamp":1714225397395,"user_tz":-480,"elapsed":4,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}}},"outputs":[],"source":["#https://www.modelscope.cn/models/LLM-Research/Phi-3-mini-128k-instruct/summary"]},{"cell_type":"code","source":["!pip install transformers modelscope"],"metadata":{"id":"dbqqtELisfaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from modelscope import snapshot_download\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ez9wHuxMsk6f","executionInfo":{"status":"ok","timestamp":1714225436646,"user_tz":-480,"elapsed":24555,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}},"outputId":"12953ce2-d80e-4713-f7d8-bb5c30640bdb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["2024-04-27 13:43:34,406 - modelscope - INFO - PyTorch version 2.2.1+cu121 Found.\n","2024-04-27 13:43:34,415 - modelscope - INFO - TensorFlow version 2.15.0 Found.\n","2024-04-27 13:43:34,417 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n","2024-04-27 13:43:34,718 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 6400a7e47afd31146a6a6e05317b3475 and a total number of 976 components indexed\n"]}]},{"cell_type":"code","source":["!pip install accelerate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDxXzXbNt6Kd","executionInfo":{"status":"ok","timestamp":1714225446186,"user_tz":-480,"elapsed":9553,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}},"outputId":"bb42828c-3c4c-4038-ee75-badc79ba18c6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}]},{"cell_type":"code","source":["torch.random.manual_seed(0)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sZiVkqzsvIN","executionInfo":{"status":"ok","timestamp":1714225447036,"user_tz":-480,"elapsed":854,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}},"outputId":"73e63d1d-a702-48be-9905-334fc7254ac7"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x79a4e666af30>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["model_dir = snapshot_download(\"LLM-Research/Phi-3-mini-128k-instruct\")"],"metadata":{"id":"Huy3EPW8tKqg","executionInfo":{"status":"ok","timestamp":1714225447886,"user_tz":-480,"elapsed":852,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(\n","    model_dir,\n","    #device_map = \"cuda\",\n","    torch_dtype = \"auto\",\n","    trust_remote_code = True,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["ccce42429e574240b42392c5dfa7c6db","bbca1917dc21442e93cfceb23d756100","d468693a69464beba1646019feb3dea7","40d4eec0fabf49d6bb48ee2ba202ff2c","49812453de4b468390627355599005b3","9b46f813072c4c748a16b8a34dbb3de5","714aa50f352049cf9777e3600114bed3","cf5eeae9ef69446d9562704dd80075ce","a7c08b2a93c74f3f9c5318040526b1da","289b17579d7d4f34865f92f4f9b03177","71888d259db74fd289556e3e519538e7"]},"id":"hyrMW3_Ws-pM","executionInfo":{"status":"ok","timestamp":1714225490964,"user_tz":-480,"elapsed":43080,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}},"outputId":"3463a7f9-36d7-4c9f-bfb3-1605e7021e59"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:transformers_modules.Phi-3-mini-128k-instruct.modeling_phi3:Flash Attention or Flash Attention Submodules not found, consider installing for better performance: No module named 'flash_attn'.\n","WARNING:transformers_modules.Phi-3-mini-128k-instruct.modeling_phi3:This version of flash does not support window size. Please use `attn_implementation='eager'` or upgrade flash-attn library.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccce42429e574240b42392c5dfa7c6db"}},"metadata":{}}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eimQdsg5tI23","executionInfo":{"status":"ok","timestamp":1714225490964,"user_tz":-480,"elapsed":10,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}},"outputId":"bcd84e46-2833-4faa-bdd1-27a8c9fb29ff"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user.\"},\n","    {\"role\": \"user\", \"content\": \"Can you provide two suggestions on how to learn deep learning?\"}\n","]"],"metadata":{"id":"4wFU2IXFu7Ue","executionInfo":{"status":"ok","timestamp":1714225490964,"user_tz":-480,"elapsed":7,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["pipe = pipeline(\n","    \"text-generation\",\n","    model = model,\n","    tokenizer = tokenizer,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fk8RxCmYvLCA","executionInfo":{"status":"ok","timestamp":1714225490964,"user_tz":-480,"elapsed":7,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}},"outputId":"d7a6b60b-707b-45ed-ec40-585bcebbd36b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["The model 'Phi3ForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"]}]},{"cell_type":"code","source":["generation_args = {\n","    \"max_new_tokens\": 500,\n","    \"return_full_text\": False,\n","    \"temperature\": 0.0,\n","    \"do_sample\": False,\n","}"],"metadata":{"id":"OckxrTbbvQ-G","executionInfo":{"status":"ok","timestamp":1714225490964,"user_tz":-480,"elapsed":6,"user":{"displayName":"gogo Leaf","userId":"10800723900909264994"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["output = pipe(messages, **generation_args)\n","print(output[0]['generated_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJqGgVNAwRel","outputId":"74d83dbe-7d54-4bdd-874e-8976c4f20c2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","WARNING:transformers_modules.Phi-3-mini-128k-instruct.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-gIkxik7wUUE"},"execution_count":null,"outputs":[]}]}